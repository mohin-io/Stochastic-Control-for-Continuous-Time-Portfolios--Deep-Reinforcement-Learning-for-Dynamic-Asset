# PPO Agent Configuration

name: "PPO"
type: "continuous"

# Network architecture
hidden_dims:
  - 256
  - 256

# Learning parameters
learning_rate: 3.0e-4
gamma: 0.99  # Discount factor

# PPO-specific
clip_epsilon: 0.2  # PPO clipping parameter
gae_lambda: 0.95  # GAE lambda
value_coef: 0.5  # Value loss coefficient
entropy_coef: 0.01  # Entropy bonus coefficient
max_grad_norm: 0.5  # Gradient clipping

# Training
n_steps: 2048  # Steps per rollout
batch_size: 64
n_epochs: 10  # Optimization epochs per rollout
